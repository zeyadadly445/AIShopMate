import { NextRequest, NextResponse } from 'next/server'
import { supabaseAdmin } from '@/lib/supabase'

interface ChatMessage {
  role: 'user' | 'assistant'
  content: string
  timestamp: string
}

export async function POST(
  request: NextRequest,
  { params }: { params: Promise<{ chatbotId: string }> }
) {
  try {
    const { chatbotId } = await params
    const { message, conversationHistory = [] } = await request.json()

    console.log('ğŸ’¬ Local chat request:', { 
      chatbotId, 
      message: message?.substring(0, 50),
      historyLength: conversationHistory.length 
    })

    if (!message?.trim()) {
      return NextResponse.json(
        { error: 'Message is required' },
        { status: 400 }
      )
    }

    // 1. Get merchant information only
    const { data: merchant, error: merchantError } = await supabaseAdmin
      .from('Merchant')
      .select(`
        id,
        businessName,
        welcomeMessage,
        primaryColor,
        dataSources:MerchantDataSource(
          type,
          title,
          url,
          isActive
        )
      `)
      .eq('chatbotId', chatbotId)
      .single()

    if (merchantError || !merchant) {
      console.log('âŒ Merchant not found:', merchantError?.message)
      return NextResponse.json({ 
        error: 'Merchant not found',
        response: 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ù…ØªØ¬Ø±.'
      }, { status: 404 })
    }

    console.log('âœ… Merchant found:', merchant.businessName)

    // 2. Prepare context for AI with business info and conversation history
    const businessContext = `
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ù…ØªØ¬Ø± "${merchant.businessName}".

Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ¬Ø±:
${merchant.dataSources?.filter((ds: any) => ds.isActive).map((ds: any) => 
  `- ${ds.type}: ${ds.title} (${ds.url})`
).join('\n') || 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ØµØ§Ø¯Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹'}

ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø©:
- ØªØ­Ø¯Ø« Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¯Ø§Ø¦Ù…Ø§Ù‹
- ÙƒÙ† Ù…Ù‡Ø°Ø¨Ø§Ù‹ ÙˆÙ…Ø³Ø§Ø¹Ø¯Ø§Ù‹ ÙˆÙˆØ¯ÙˆØ¯Ø§Ù‹
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ù…Ù†ØªØ¬Ø§Øª ÙˆØ®Ø¯Ù…Ø§Øª "${merchant.businessName}"
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø£ÙØ¶Ù„
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø­Ø¯Ø¯Ø©ØŒ Ø§Ù†ØµØ­ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¨Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù…ØªØ¬Ø± Ù…Ø¨Ø§Ø´Ø±Ø©
- Ù„Ø§ ØªØªØ­Ø¯Ø« Ø¹Ù† Ù…ØªØ§Ø¬Ø± Ø£Ø®Ø±Ù‰ Ø£Ùˆ Ù…Ù†Ø§ÙØ³ÙŠÙ†
- Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø·Ø§Ø¨Ø¹ Ø§Ù„Ù…Ù‡Ù†ÙŠ ÙˆØ§Ù„ÙˆØ¯ÙˆØ¯
- Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙÙŠØ¯Ø© ÙˆØ¹Ù…Ù„ÙŠØ© Ù„Ù„Ø¹Ù…Ù„Ø§Ø¡

Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:
${conversationHistory.slice(-10).map((msg: ChatMessage) => 
  `${msg.role === 'user' ? 'Ø§Ù„Ø¹Ù…ÙŠÙ„' : 'Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯'}: ${msg.content}`
).join('\n')}
`

    // 3. Generate AI response
    let aiResponse = generateSmartFallback(message, merchant.businessName, conversationHistory)
    let aiDebug: any = { success: false, error: 'not attempted', stage: 'init' }

    try {
      const chuteAIApiKey = process.env.CHUTES_AI_API_KEY
      const chuteAIUrl = process.env.CHUTES_AI_API_URL || 'https://llm.chutes.ai/v1/chat/completions'

      if (!chuteAIApiKey) {
        aiDebug = { success: false, error: 'API key not found', stage: 'env_check' }
        console.log('âš ï¸ AI API key not found, using smart fallback')
        return NextResponse.json({ 
          response: aiResponse,
          debug: { aiDebug, merchant: merchant.businessName, fallbackUsed: true }
        })
      }

      // Calculate dynamic max tokens based on context
      const baseTokens = 1000
      const messageLength = message.length
      const historyLength = conversationHistory.length
      const contextLength = businessContext.length
      
      let maxTokens = baseTokens
      maxTokens += Math.min(messageLength * 2, 5000)
      maxTokens += Math.min(historyLength * 100, 3000)
      maxTokens += Math.min(contextLength / 10, 2000)
      maxTokens = Math.min(maxTokens, 8000) // Reasonable limit for faster responses

      console.log('ğŸ¤– Calling AI API...', { maxTokens, historyLength, messageLength: message.length })
      aiDebug.stage = 'calling_api'

      const requestBody = {
        model: process.env.CHUTES_AI_MODEL || 'deepseek-ai/DeepSeek-V3-0324',
        messages: [
          {
            role: 'user',
            content: `${businessContext}\n\nØ±Ø³Ø§Ù„Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: ${message}`
          }
        ],
        max_tokens: maxTokens,
        temperature: 0.7,
        stream: false
      }

      // Try with retry mechanism
      let response: Response | null = null
      let lastError = ''
      
      for (let attempt = 1; attempt <= 3; attempt++) {
        try {
          console.log(`ğŸ”„ AI API attempt ${attempt}/3`)
          
          response = await fetch(chuteAIUrl, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${chuteAIApiKey}`
            },
            body: JSON.stringify(requestBody),
            signal: AbortSignal.timeout(10000) // 10 second timeout
          })
          
          if (response.ok) {
            console.log(`âœ… AI API succeeded on attempt ${attempt}`)
            break
          } else {
            lastError = `HTTP ${response.status}: ${await response.text()}`
            console.log(`âŒ AI API failed attempt ${attempt}: ${lastError}`)
            if (attempt < 3) {
              await new Promise(resolve => setTimeout(resolve, 1000 * attempt)) // Progressive delay
            }
          }
        } catch (fetchError) {
          lastError = fetchError instanceof Error ? fetchError.message : String(fetchError)
          console.log(`âŒ AI API error attempt ${attempt}: ${lastError}`)
          if (attempt < 3) {
            await new Promise(resolve => setTimeout(resolve, 1000 * attempt))
          }
        }
      }

      if (!response || !response.ok) {
        aiDebug = { 
          success: false, 
          error: `All retry attempts failed. Last error: ${lastError}`, 
          stage: 'retry_exhausted',
          attempts: 3
        }
        console.log('âŒ All AI API retry attempts failed, using smart fallback')
        
        // Update the smart fallback to indicate AI unavailable
        aiResponse = generateSmartFallback(message, merchant.businessName, conversationHistory) + 
                    '\n\n*Ù…Ù„Ø§Ø­Ø¸Ø©: Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ù…Ø¤Ù‚ØªØ§Ù‹ØŒ Ù„ÙƒÙ†Ù†ÙŠ Ø³Ø¹ÙŠØ¯ Ø¨Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ!*'
        
        return NextResponse.json({ 
          response: aiResponse,
          merchant: {
            businessName: merchant.businessName,
            primaryColor: merchant.primaryColor
          },
          timestamp: new Date().toISOString(),
          status: 'fallback_used',
          debug: {
            ai: aiDebug,
            contextLength: businessContext.length,
            historyLength: conversationHistory.length,
            messageLength: message.length,
            fallbackUsed: true
          }
        })
      }

      aiDebug.stage = 'response_received'
      
      if (response.ok) {
        const data = await response.json()
        aiDebug.stage = 'parsing_response'
        
        console.log('ğŸ“ AI API Response structure:', {
          hasChoices: !!data.choices,
          choicesLength: data.choices?.length,
          hasContent: !!data.choices?.[0]?.message?.content,
          contentLength: data.choices?.[0]?.message?.content?.length
        })
        
        if (data.choices?.[0]?.message?.content) {
          const rawResponse = data.choices[0].message.content.trim()
          
          // Clean up common prefixes
          aiResponse = rawResponse.replace(/^(Ù…Ø³Ø§Ø¹Ø¯|Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯|Ø£Ù†Ø§|Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ?|Ø£Ù‡Ù„Ø§Ù‹ØŒ?)\s*/i, '')
          
          // If cleaning removed everything, use original
          if (!aiResponse.trim()) {
            aiResponse = rawResponse
          }
          
          aiDebug = { 
            success: true, 
            error: null, 
            stage: 'success',
            rawLength: rawResponse.length,
            cleanedLength: aiResponse.length,
            wasCleaned: rawResponse !== aiResponse
          }
          
          console.log('âœ… AI response generated successfully', {
            originalLength: rawResponse.length,
            finalLength: aiResponse.length
          })
        } else {
          aiDebug = { 
            success: false, 
            error: 'No content in AI response', 
            stage: 'no_content',
            responseStructure: Object.keys(data)
          }
          console.log('âŒ AI response has no content:', data)
        }
      } else {
        const errorText = await response.text()
        aiDebug = { 
          success: false, 
          error: `HTTP ${response.status}: ${errorText}`, 
          stage: 'http_error',
          status: response.status,
          statusText: response.statusText
        }
        console.log('âš ï¸ AI API failed:', response.status, response.statusText, errorText)
      }

    } catch (aiError) {
      aiDebug = { 
        success: false, 
        error: aiError instanceof Error ? aiError.message : String(aiError), 
        stage: 'exception',
        errorType: aiError instanceof Error ? aiError.constructor.name : typeof aiError
      }
      console.log('âš ï¸ AI error, using fallback:', aiError)
    }

    // 4. Return response (no database saving)
    return NextResponse.json({ 
      response: aiResponse,
      merchant: {
        businessName: merchant.businessName,
        primaryColor: merchant.primaryColor
      },
      timestamp: new Date().toISOString(),
      status: 'success_local_only',
      debug: {
        ai: aiDebug,
        contextLength: businessContext.length,
        historyLength: conversationHistory.length,
        messageLength: message.length
      }
    })

  } catch (error) {
    console.error('ğŸ’¥ Chat error:', error)
    return NextResponse.json(
      { 
        error: 'Internal server error',
        response: 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',
        details: error instanceof Error ? error.message : 'Unknown error'
      },
      { status: 500 }
    )
  }
}

// Smart fallback response generator
function generateSmartFallback(message: string, businessName: string, conversationHistory: ChatMessage[]): string {
  const lowerMessage = message.toLowerCase().trim()
  
  // Check for greetings
  const greetings = ['Ù…Ø±Ø­Ø¨Ø§', 'Ù‡Ù„Ø§', 'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…', 'Ø£Ù‡Ù„Ø§', 'ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±', 'Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±', 'hi', 'hello']
  if (greetings.some(greeting => lowerMessage.includes(greeting))) {
    const timeBasedGreeting = new Date().getHours() < 12 ? 'ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±' : 'Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±'
    return `${timeBasedGreeting}! Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù…ØªØ¬Ø± ${businessName}. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ ğŸ˜Š`
  }
  
  // Check for product inquiries
  const productQuestions = ['Ø¹Ù†Ø¯ÙƒÙ…', 'Ù…ØªÙˆÙØ±', 'Ù…ÙˆØ¬ÙˆØ¯', 'Ø£Ø³Ø¹Ø§Ø±', 'ÙƒÙ… Ø³Ø¹Ø±', 'Ø¨ÙƒØ§Ù…', 'Ù…Ù†ØªØ¬Ø§Øª']
  if (productQuestions.some(word => lowerMessage.includes(word))) {
    return `Ø¨Ø§Ù„Ø·Ø¨Ø¹! Ù„Ø¯ÙŠÙ†Ø§ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø±Ø§Ø¦Ø¹Ø© ÙÙŠ ${businessName}. Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø­Ø¯Ø« Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª ÙˆØ§Ù„Ø£Ø³Ø¹Ø§Ø±ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØµÙØ­ Ù…ØªØ¬Ø±Ù†Ø§ Ø£Ùˆ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©. Ù‡Ù„ ØªØ¨Ø­Ø« Ø¹Ù† Ø´ÙŠØ¡ Ù…Ø­Ø¯Ø¯ØŸ`
  }
  
  // Check for questions
  const questionWords = ['ÙƒÙŠÙ', 'Ù…ØªÙ‰', 'Ø£ÙŠÙ†', 'Ù…Ø§Ø°Ø§', 'Ù‡Ù„', 'Ù„ÙŠÙ‡', 'Ø¥Ø²Ø§ÙŠ']
  if (questionWords.some(word => lowerMessage.includes(word)) || lowerMessage.includes('ØŸ')) {
    return `Ø³Ø¤Ø§Ù„ Ù…Ù…ØªØ§Ø²! Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ${businessName}. Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙØµÙ„Ø©ØŒ Ø£Ù†ØµØ­Ùƒ Ø¨Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ ÙØ±ÙŠÙ‚Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø±ØŸ`
  }
  
  // Check for complaints or negative words
  const negativeWords = ['Ù…Ø´ÙƒÙ„Ø©', 'Ø®Ø±Ø§Ø¨', 'Ø³ÙŠØ¡', 'ÙˆØ­Ø´', 'Ø­Ù…Ø§Ø±', 'ØºØ¨ÙŠ']
  if (negativeWords.some(word => lowerMessage.includes(word))) {
    return `Ø£Ø¹ØªØ°Ø± Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ø¥Ø²Ø¹Ø§Ø¬. Ù†Ø­Ù† ÙÙŠ ${businessName} Ù†Ø­Ø±Øµ Ø¹Ù„Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø£ÙØ¶Ù„ Ø®Ø¯Ù…Ø©. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ØªØ¬Ø± Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ø­Ù„ Ø£ÙŠ Ù…Ø´ÙƒÙ„Ø©. Ù†Ù‚Ø¯Ø± ØµØ¨Ø±Ùƒ ÙˆØªÙÙ‡Ù…Ùƒ ğŸ™`
  }
  
  // Check for thanks
  const thankWords = ['Ø´ÙƒØ±Ø§', 'Ù…Ø´ÙƒÙˆØ±', 'ØªØ³Ù„Ù…', 'Ø§Ù„Ù„Ù‡ ÙŠØ¹Ø·ÙŠÙƒ Ø§Ù„Ø¹Ø§ÙÙŠØ©']
  if (thankWords.some(word => lowerMessage.includes(word))) {
    return `Ø§Ù„Ø¹ÙÙˆ! Ø³Ø¹Ø¯Ø§Ø¡ Ø¨Ø®Ø¯Ù…ØªÙƒ ÙÙŠ ${businessName}. Ù†Ø­Ù† Ù‡Ù†Ø§ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ. Ù‡Ù„ ØªØ­ØªØ§Ø¬ Ù„Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø±ØŸ ğŸ˜Š`
  }
  
  // Check for contact/location questions
  const contactWords = ['ÙÙŠÙ†', 'Ø¹Ù†ÙˆØ§Ù†', 'Ù…ÙˆÙ‚Ø¹', 'ØªÙ„ÙŠÙÙˆÙ†', 'Ø±Ù‚Ù…', 'ØªÙˆØ§ØµÙ„']
  if (contactWords.some(word => lowerMessage.includes(word))) {
    return `ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù€ ${businessName} ÙÙŠ ØµÙØ­ØªÙ†Ø§ Ø£Ùˆ Ù…ØªØ¬Ø±Ù†Ø§. Ù†Ø­Ù† Ù…ØªØ§Ø­ÙˆÙ† Ù„Ø®Ø¯Ù…ØªÙƒ! ğŸ“`
  }
  
  // Check conversation history for context
  if (conversationHistory.length > 1) {
    const lastMessage = conversationHistory[conversationHistory.length - 2]?.content || ''
    if (lastMessage.includes('Ù…Ø±Ø­Ø¨') || lastMessage.includes('Ø£Ù‡Ù„Ø§')) {
      return `Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ… ÙÙŠ ${businessName}ØŸ`
    }
  }
  
  // Default intelligent response
  const responses = [
    `Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙˆØ§ØµÙ„Ùƒ Ù…Ø¹ ${businessName}! Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ. ÙŠÙ…ÙƒÙ†Ùƒ Ø³Ø¤Ø§Ù„ÙŠ Ø¹Ù† Ø£ÙŠ Ø´ÙŠØ¡ ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØªÙ‡.`,
    `Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ ${businessName}! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ`,
    `Ø£Ù‡Ù„Ø§Ù‹! Ø³Ø¹Ø¯Ø§Ø¡ Ø¨ÙˆØ¬ÙˆØ¯Ùƒ ÙÙŠ ${businessName}. Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ¨Ø­Ø« Ø¹Ù†Ù‡ Ø§Ù„ÙŠÙˆÙ…ØŸ`
  ]
  
  return responses[Math.floor(Math.random() * responses.length)]
} 