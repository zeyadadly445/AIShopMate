import { NextRequest, NextResponse } from 'next/server'
import { supabaseAdmin } from '@/lib/supabase'

interface ChatMessage {
  role: 'user' | 'assistant'
  content: string
  timestamp: string
}

export async function POST(
  request: NextRequest,
  { params }: { params: Promise<{ chatbotId: string }> }
) {
  try {
    const { chatbotId } = await params
    const { message, conversationHistory = [] } = await request.json()

    console.log('ğŸ’¬ Local chat request:', { 
      chatbotId, 
      message: message?.substring(0, 50),
      historyLength: conversationHistory.length 
    })

    if (!message?.trim()) {
      return NextResponse.json(
        { error: 'Message is required' },
        { status: 400 }
      )
    }

    // 1. Get merchant information only
    const { data: merchant, error: merchantError } = await supabaseAdmin
      .from('Merchant')
      .select(`
        id,
        businessName,
        welcomeMessage,
        primaryColor,
        dataSources:MerchantDataSource(
          type,
          title,
          url,
          isActive
        )
      `)
      .eq('chatbotId', chatbotId)
      .single()

    if (merchantError || !merchant) {
      console.log('âŒ Merchant not found:', merchantError?.message)
      return NextResponse.json({ 
        error: 'Merchant not found',
        response: 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ù…ØªØ¬Ø±.'
      }, { status: 404 })
    }

    console.log('âœ… Merchant found:', merchant.businessName)

    // 2. Check if AI key exists
    const chuteAIApiKey = process.env.CHUTES_AI_API_KEY

    if (!chuteAIApiKey) {
      console.log('âš ï¸ AI API key not found, using smart fallback')
      return NextResponse.json({ 
        response: generateSmartFallback(message, merchant.businessName, conversationHistory),
        merchant: {
          businessName: merchant.businessName,
          primaryColor: merchant.primaryColor
        },
        status: 'fallback_no_key'
      })
    }

    // 3. Create REAL streaming response
    console.log('ğŸš€ Creating real-time streaming response...')
    
    const encoder = new TextEncoder()
    
    const stream = new ReadableStream({
      async start(controller) {
        try {
          console.log('ğŸ“¡ Starting AI streaming request...')
          
          const response = await fetch('https://llm.chutes.ai/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${chuteAIApiKey}`,
              'Content-Type': 'application/json'
            },
            body: JSON.stringify({
              model: 'deepseek-ai/DeepSeek-V3-0324',
              messages: [
                {
                  role: 'user',
                  content: `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ù…ØªØ¬Ø± "${merchant.businessName}". Ø±Ø¯ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ Ù…ÙØµÙ„ ÙˆÙ…ÙÙŠØ¯ Ø¹Ù„Ù‰: ${message}`
                }
              ],
              stream: true,
              max_tokens: 128000,
              temperature: 0.7
            })
          })
          
          if (!response.ok) {
            console.log('âŒ AI request failed, sending fallback')
            const fallback = generateSmartFallback(message, merchant.businessName, conversationHistory)
            
            // Send fallback as JSON
            controller.enqueue(encoder.encode(JSON.stringify({
              response: fallback,
              merchant: {
                businessName: merchant.businessName,
                primaryColor: merchant.primaryColor
              },
              status: 'fallback_ai_error'
            })))
            controller.close()
            return
          }
          
          if (!response.body) {
            throw new Error('No response body')
          }
          
          // Send initial metadata
          controller.enqueue(encoder.encode(JSON.stringify({
            type: 'start',
            merchant: {
              businessName: merchant.businessName,
              primaryColor: merchant.primaryColor
            },
            status: 'streaming'
          }) + '\n'))
          
          console.log('âœ… Starting real-time streaming...')
          
          const reader = response.body.getReader()
          const decoder = new TextDecoder()
          
          while (true) {
            const { done, value } = await reader.read()
            
            if (done) {
              console.log('âœ… Stream completed')
              // Send completion signal
              controller.enqueue(encoder.encode(JSON.stringify({
                type: 'done'
              }) + '\n'))
              break
            }
            
            const chunk = decoder.decode(value, { stream: true })
            const lines = chunk.split('\n')
            
            for (const line of lines) {
              if (line.startsWith('data: ')) {
                const data = line.slice(6).trim()
                
                if (data === '[DONE]') {
                  console.log('âœ… AI stream finished')
                  controller.enqueue(encoder.encode(JSON.stringify({
                    type: 'done'
                  }) + '\n'))
                  break
                }
                
                try {
                  const parsed = JSON.parse(data)
                  const content = parsed.choices?.[0]?.delta?.content
                  
                  if (content) {
                    // Send each piece immediately to client
                    controller.enqueue(encoder.encode(JSON.stringify({
                      type: 'content',
                      content: content
                    }) + '\n'))
                  }
                } catch (parseError) {
                  // Skip invalid chunks
                  console.log('âš ï¸ Skipping invalid JSON chunk')
                }
              }
            }
          }
          
          controller.close()
          
        } catch (error) {
          console.error('ğŸ’¥ Streaming error:', error)
          
          // Send fallback on error
          const fallback = generateSmartFallback(message, merchant.businessName, conversationHistory)
          controller.enqueue(encoder.encode(JSON.stringify({
            type: 'fallback',
            response: fallback,
            merchant: {
              businessName: merchant.businessName,
              primaryColor: merchant.primaryColor
            },
            error: error instanceof Error ? error.message : String(error)
          }) + '\n'))
          
          controller.close()
        }
      }
    })
    
    return new Response(stream, {
      headers: {
        'Content-Type': 'text/plain; charset=utf-8',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
        'X-Accel-Buffering': 'no'
      }
    })

  } catch (error) {
    console.error('ğŸ’¥ Chat error:', error)
    return NextResponse.json(
      { 
        error: 'Internal server error',
        response: 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',
        details: error instanceof Error ? error.message : 'Unknown error'
      },
      { status: 500 }
    )
  }
}

// Smart fallback response generator
function generateSmartFallback(message: string, businessName: string, conversationHistory: ChatMessage[]): string {
  const lowerMessage = message.toLowerCase().trim()
  
  // Check for greetings
  const greetings = ['Ù…Ø±Ø­Ø¨Ø§', 'Ù‡Ù„Ø§', 'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…', 'Ø£Ù‡Ù„Ø§', 'ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±', 'Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±', 'hi', 'hello']
  if (greetings.some(greeting => lowerMessage.includes(greeting))) {
    const timeBasedGreeting = new Date().getHours() < 12 ? 'ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±' : 'Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±'
    return `${timeBasedGreeting}! Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù…ØªØ¬Ø± ${businessName}. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ ğŸ˜Š`
  }
  
  // Check for product inquiries
  const productQuestions = ['Ø¹Ù†Ø¯ÙƒÙ…', 'Ù…ØªÙˆÙØ±', 'Ù…ÙˆØ¬ÙˆØ¯', 'Ø£Ø³Ø¹Ø§Ø±', 'ÙƒÙ… Ø³Ø¹Ø±', 'Ø¨ÙƒØ§Ù…', 'Ù…Ù†ØªØ¬Ø§Øª']
  if (productQuestions.some(word => lowerMessage.includes(word))) {
    return `Ø¨Ø§Ù„Ø·Ø¨Ø¹! Ù„Ø¯ÙŠÙ†Ø§ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø±Ø§Ø¦Ø¹Ø© ÙÙŠ ${businessName}. Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø­Ø¯Ø« Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª ÙˆØ§Ù„Ø£Ø³Ø¹Ø§Ø±ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØµÙØ­ Ù…ØªØ¬Ø±Ù†Ø§ Ø£Ùˆ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©. Ù‡Ù„ ØªØ¨Ø­Ø« Ø¹Ù† Ø´ÙŠØ¡ Ù…Ø­Ø¯Ø¯ØŸ`
  }
  
  // Check for questions
  const questionWords = ['ÙƒÙŠÙ', 'Ù…ØªÙ‰', 'Ø£ÙŠÙ†', 'Ù…Ø§Ø°Ø§', 'Ù‡Ù„', 'Ù„ÙŠÙ‡', 'Ø¥Ø²Ø§ÙŠ']
  if (questionWords.some(word => lowerMessage.includes(word)) || lowerMessage.includes('ØŸ')) {
    return `Ø³Ø¤Ø§Ù„ Ù…Ù…ØªØ§Ø²! Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ${businessName}. Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙØµÙ„Ø©ØŒ Ø£Ù†ØµØ­Ùƒ Ø¨Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ ÙØ±ÙŠÙ‚Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø±ØŸ`
  }
  
  // Check for complaints or negative words
  const negativeWords = ['Ù…Ø´ÙƒÙ„Ø©', 'Ø®Ø±Ø§Ø¨', 'Ø³ÙŠØ¡', 'ÙˆØ­Ø´', 'Ø­Ù…Ø§Ø±', 'ØºØ¨ÙŠ']
  if (negativeWords.some(word => lowerMessage.includes(word))) {
    return `Ø£Ø¹ØªØ°Ø± Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ø¥Ø²Ø¹Ø§Ø¬. Ù†Ø­Ù† ÙÙŠ ${businessName} Ù†Ø­Ø±Øµ Ø¹Ù„Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø£ÙØ¶Ù„ Ø®Ø¯Ù…Ø©. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ØªØ¬Ø± Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ø­Ù„ Ø£ÙŠ Ù…Ø´ÙƒÙ„Ø©. Ù†Ù‚Ø¯Ø± ØµØ¨Ø±Ùƒ ÙˆØªÙÙ‡Ù…Ùƒ ğŸ™`
  }
  
  // Check for thanks
  const thankWords = ['Ø´ÙƒØ±Ø§', 'Ù…Ø´ÙƒÙˆØ±', 'ØªØ³Ù„Ù…', 'Ø§Ù„Ù„Ù‡ ÙŠØ¹Ø·ÙŠÙƒ Ø§Ù„Ø¹Ø§ÙÙŠØ©']
  if (thankWords.some(word => lowerMessage.includes(word))) {
    return `Ø§Ù„Ø¹ÙÙˆ! Ø³Ø¹Ø¯Ø§Ø¡ Ø¨Ø®Ø¯Ù…ØªÙƒ ÙÙŠ ${businessName}. Ù†Ø­Ù† Ù‡Ù†Ø§ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ. Ù‡Ù„ ØªØ­ØªØ§Ø¬ Ù„Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø±ØŸ ğŸ˜Š`
  }
  
  // Check for contact/location questions
  const contactWords = ['ÙÙŠÙ†', 'Ø¹Ù†ÙˆØ§Ù†', 'Ù…ÙˆÙ‚Ø¹', 'ØªÙ„ÙŠÙÙˆÙ†', 'Ø±Ù‚Ù…', 'ØªÙˆØ§ØµÙ„']
  if (contactWords.some(word => lowerMessage.includes(word))) {
    return `ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù€ ${businessName} ÙÙŠ ØµÙØ­ØªÙ†Ø§ Ø£Ùˆ Ù…ØªØ¬Ø±Ù†Ø§. Ù†Ø­Ù† Ù…ØªØ§Ø­ÙˆÙ† Ù„Ø®Ø¯Ù…ØªÙƒ! ğŸ“`
  }
  
  // Check conversation history for context
  if (conversationHistory.length > 1) {
    const lastMessage = conversationHistory[conversationHistory.length - 2]?.content || ''
    if (lastMessage.includes('Ù…Ø±Ø­Ø¨') || lastMessage.includes('Ø£Ù‡Ù„Ø§')) {
      return `Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ… ÙÙŠ ${businessName}ØŸ`
    }
  }
  
  // Default intelligent response
  const responses = [
    `Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙˆØ§ØµÙ„Ùƒ Ù…Ø¹ ${businessName}! Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ. ÙŠÙ…ÙƒÙ†Ùƒ Ø³Ø¤Ø§Ù„ÙŠ Ø¹Ù† Ø£ÙŠ Ø´ÙŠØ¡ ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØªÙ‡.`,
    `Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ ${businessName}! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ`,
    `Ø£Ù‡Ù„Ø§Ù‹! Ø³Ø¹Ø¯Ø§Ø¡ Ø¨ÙˆØ¬ÙˆØ¯Ùƒ ÙÙŠ ${businessName}. Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ¨Ø­Ø« Ø¹Ù†Ù‡ Ø§Ù„ÙŠÙˆÙ…ØŸ`
  ]
  
  return responses[Math.floor(Math.random() * responses.length)]
} 